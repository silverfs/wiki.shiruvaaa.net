{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started \u2728","text":"<p>Welcome to my personal wiki, where I store all my findings, manuals and so forth! When I learn something new, I\u2019ll do my best to write it down here.</p> <p>Browse in the nav bar to check up on my projects or use the search bar to find something specific :3</p> <p>Consider visiting my personal website, or my Story hub! \ud83d\ude0a</p> <p></p> <p>Info</p> <p>If you like what you are reading and want something published here (or you want to write it yourself), just let me know on Discord or Github.</p>"},{"location":"docker/","title":"Docker in 2 minutes","text":""},{"location":"docker/#what-is-docker","title":"What is Docker?","text":"<p>Docker is a platform for developing, shipping, and running applications in containers. It uses a virtualization technology that makes it easier to develop and deploy apps inside of neatly packaged virtual containerized environments. Meaning, applications run the same, no matter where they are or what machine they are running on.</p> <p>Docker containers can be deployed to just about any machine without any compatibility issues. your software stays system agnostic, making software simpler to use, less work to develop and easier to maintain and deploy. These containers running on your computer or server act like little micro computers, each with very specific jobs, each with their own OS, their isolated CPU processes, memory and network resources. Because of this, they can be easily added, removed, stopped and started again without affecting each other or the host machine. Containers usually run one specific task, such as a MySQL database or a NodeJS application. They can be networked together and potentially be scaled as well.</p> <p>Docker is a form of virtualization, but, unlike normal virtual machines, the resources are shared directly with the host. Not only that, but Docker uses less disk space as well, as it is able to reuse files efficiently by using a layered file system. </p> <p></p>"},{"location":"docker/cool%20FOSS%20projects/","title":"Cool (FOSS) Projects","text":"<p>Info</p> <p>I\u2019m not affiliated with any of the mentioned projects and services. I have simply taken a liking to them and would like to show others how nice they are to use with your own Docker instance.</p>"},{"location":"docker/cool%20FOSS%20projects/#my-recommendations","title":"My Recommendations","text":""},{"location":"docker/cool%20FOSS%20projects/#portainer","title":"Portainer","text":"<p>Portainer is a lightweight service delivery platform for containerized applications that can be used to manage Docker, Docker Swarm, Kubernetes, and ACI environments. Meaning: a GUI for your containers, Images, Volumes and more (Super cool!). </p> <p> </p> <p>Installation is really easy! Follow these links to the documentation that suits you best: - Portainer-CE - - Portainer-BE</p>"},{"location":"docker/installation%20methods/","title":"Installation","text":"<p>I\u2019m not here to describe you in every single detail how to install Docker on your system. If you want every possible detail there is, I\u2019d advice you to head over to the official documentation. What I want to discuss here are the most common installations, as simple as possible. So without further ado, let\u2019s dive right into it.</p>"},{"location":"docker/installation%20methods/#windows","title":"Windows","text":"<p>I\u2019d advice you to install your Docker instance on a Linux machine or Linux subsystem, but if you have no other choice or just really want to do it on your Windows pc without WSL, it\u2019s possible. In order for you to work with Docker without a WSL2 backend, we need to make use of a Hyper-V backend and Windows containers, but we\u2019ll come back later on that.</p> <p>Warning</p> <p>To run Windows containers, you need Windows 10/11, with either Professional or Enterprise edition. The Windows Home or Education editions will only allow you to run Linux containers.</p> <p> </p> <p>You can download Docker Desktop for Windows directly or, if that doesn\u2019t work, through the website and execute the program.</p> <p>When executing the program, you will be prompted to choose between WSL2 and Hyper-V, You\u2019ll have to choose the Hyper-V option (if you are not able to select an option, that means your system does not support it). If you do support the WSL2 option, you can check that one to continue the installation here</p> <p>Next, follow the instructions the wizard gives you and finalize the installation. When successful, click close to complete the installation process.</p> <p>Great! You have now successfully installed Docker Desktop. You\u2019ll be able to start and view your containers, search in your image-list, and more; all from a neat GUI. </p>"},{"location":"docker/installation%20methods/#wsl2","title":"WSL2","text":"<p>WSL (or Windows Subsystem for Linux) is there for developers to run a GNU/Linux environment, including most command-line tools, utilities and applications directly on Windows. This requires no virtual machine or a dualboot setup and runs with your Windows installation. In order to work with WSL, we\u2019ll have to install it first.</p> <p>Check if you\u2019ve already installed WSL before with this command: <pre><code>wsl\n</code></pre></p> <p>If a bash terminal inside your normal terminal doesn\u2019t appear, it means you don\u2019t have WSL yet. Install WSL with the following command: <pre><code>wsl --install\n</code></pre></p> <p>It should tell you afterwards that the operation was successful. You have installed Ubuntu as your Linux Distribution. You can now continue where you left off in the windows part, by downloading the application and following the magical instructions.</p> <p></p>"},{"location":"docker/installation%20methods/#gnulinux","title":"GNU/Linux","text":"<p>Coming soon \u2122\ufe0f</p>"},{"location":"docker/the%20basics%20of%20docker%20and%20virtualization/","title":"The Basics of Docker and Virtualization","text":""},{"location":"docker/the%20basics%20of%20docker%20and%20virtualization/#pre-virtualization-world","title":"Pre-Virtualization World","text":"<p>In the pre-virtualization days, we used big server racks. Underneath, we had the physical server. we installed the desired Operating System on it and run the application on top of the operating system. Each physical machine would run only one application. You can already guess where I\u2019m going to\u2026</p> <p> </p> <p>There are some problems with this model. First of all, we have to purchase a physical machine. Believe me, those can be very expensive. We might end up only using a fraction of the CPU or a memory of the machine. The rest of the resources would be simply wasted. Secondly, deployment time is often slow. The process of purchasing and configuring your physical server can take ages; especially for big organizations. Thirdly, it would be painful to migrate our applications to servers from different vendors. </p> <p> </p> <p>Underneath we have the physical server. There, we would install the desired Operating System. On top of the OS, a hypervisor layer is introduced which allows us to install multiple virtual machines (VM) on a physical machine. Each VM can have a different Operating system. In this way, we can run multiple Operating Systems, on a single physical machine and each Operating System can run a different application. This is the traditional model of virtualization which is being referenced as the hypervisor-based virtualization. Some of the popular hypervisor providers are VMware and VirtualBox. In the early stage, users would deploy VM\u2019s on their own physical servers, but nowadays, more and more companies have been shifted to deploy VM\u2019s in the cloud with providers such as AWS and Microsoft.</p> <p>There are some huge benefits with this model. First of all, it is more cost efficient. Each physical machine is divided into multiple VM\u2019s and each one only uses it\u2019s own CPU, memory and storage resources. We pay only for the compute power storage and other resources you use with no upfront commitments which is a typical pay-as-you-go model. Secondly, it\u2019s easy to scale with VM\u2019s deployed in the cloud environment. If we wanted more instances of our application, we don\u2019t need to go through the long process of ordering and configuring new physical servers. We can simply deploy a new VM with one click of a mouse. This reduces the time to configure and deploy from weeks to minutes!</p> <p>of-course, it still has limitations:</p> <p>First of all, each VM still needs to have an OS installed. This means that each VM has a full OS with it\u2019s own memory management, device drivers, daemons, etc. We would have to run a whole OS on one server, simply for one application. Secondly, application portability is not guaranteed. Some progress had been achieved in getting virtual machines to run across different types of hypervisors, there is still a lot of work to be done there. VM portability is still at an early stage.</p>"},{"location":"docker/the%20basics%20of%20docker%20and%20virtualization/#container-based-virtualization","title":"Container-based Virtualization","text":"<p>Finally, the Container virtualization technology was dropped. Docker is an implementation of container-based virtualization technologies. Let\u2019s take a look at this diagram here. </p> <p> </p> <p>Underneath, we have our server. This can either be a physical machine, or a virtual machine. Then, we install the operating system on the server. on top of the OS, we install a container engine, which allows us to run multiple guest instances. Each guest instance is called a container. Within each container we install the application and all the libraries that the application depends on.</p> <p>The key to understand the difference between the hypervisor-based virtualization model and the container-based model, is the replication of the models. In the traditional model, each application is running in it\u2019s own copy of the kernel and the virtualization happens at the hardware level. In the new model, we only have one model which has supplied different binaries and runtime to the applications running in isolated containers. So, the container has shared the base runtime kernel, which is the container engine. For the new model, the virtualization happens at the operating system level. Containers shared the host\u2019s OS and is thus much more efficient and light-weighted.</p>"},{"location":"docker/what%20is%20docker%20swarm/","title":"What is Docker Swarm?","text":""},{"location":"docker/what%20is%20docker%20swarm/#clusters","title":"Clusters","text":"<p>Docker Swarm is a tool that \u201cclusters\u201d many Docker Engines and schedules containers. Docker Swarm decides which host to run the container based on your scheduling methods.</p> <p>Let\u2019s say you have a couple of Docker hosts. each host, has their own Docker Deamon. The swarm manager will connect each and every Docker Deamon based on your discovery method. The Swarm manger then knows the status of every host in the cluster. If you decide to run a container, the Swarm manager will decide on which container it runs. The work load will be divided by the \u201cwork nodes\u201d in the swarm and is transparent to the end users.</p> <p>So, basically, Docker Swarm can group multiple hosts into a cluster and distribute docker containers among these hosts.</p> <p> </p>"},{"location":"tips-and-tricks/windows/","title":"Windows: Tips &amp; Tricks","text":"<p>Welcome to your favourite info-centre! This documentation corner contains Tips and Tricks for Windows related situations, used for better overview, functionality, privacy, and useful tools to help you on your way!</p> <p>Select a topic in the sidebar to get started.</p>"}]}